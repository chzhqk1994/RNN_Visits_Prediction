# RNN_Visits_Prediction
---
## Facebook의 posts 수에 따른 page_impressions 를 예측
---


* 1일차 (2017. 11. 27)
    * 프로젝트 시작
    * 개발방향 토론
    * 데이터베이스와 파이썬 연동

* 2일차
    * DB 내용을 Dictionary 형태로 불러와서 csv 파일로 저장
    * 아직 Training data를 어떻게 만들어야 할지 모르겠어서 정렬기준은 정하지 못함, 일단 key 값으로 정렬하여 저장

* 3일차
    * Facebook 에서 제공하는 DB에 문제가 있어 page_impression을 예측하기 위해서 어떤 Neural Network를 이용해야 하는지 조사
    * 교수님 말씀으론 기훈이형이 사용했던 RNN 모델을 사용해보는것도 좋을거라고 하심
    * 근데 게시물 수에 따른 방문자수 예측인데 timestamp 가 굳이 필요할까

* 4일차
    * 어제 RNN에 대해서 검색을 해보며 공부를 해봤다.
    * 오늘은 주식 성장률을 예측하는 RNN 모델을 가져와서 page_impressisons을 예측하는 모델로 수정해 볼 것이다.

* 5일차
    * 주식 성장률을 예측하는 RNN 모델을 가져와서 코드를 분석하며 내 프로젝트에 맞춰서 수정하고 있다.
    * 아직 page_impressions과 posts사이의 관계를 알수없어 임의로 dataset을 만들어서 테스트를 하고 있다.
    * predict_page_impressions_test 폴더의 rnn.py 파일은 예측된 그래프가 변형된 상태로 나와버린다. 이거 어떻게 원래대로 늘려놓지
    * RNN_test 폴더의 LSTM_RNN.py 파일은 예측된 그래프가 변형되지 않은 모습으로 나타난다. 예측은 잘 되는것 같은데 다른 Dataset 으로 테스트 해볼 필요가 있다.
    * Paul이 얼른 제대로된 데이터를 내놔야 한다. 지금 주어진 Dataset은 넘나 이상하다. 빨리 내놔요 Paul님 현기증난다구




* 8일차
    * 현재 수정하고 있는 모델이 Tensorflow 말고 Keras를 이용하여 설계된 모델이라 Keras를 공부하고 있다. 확실히 Tensorflow 보단 간단한듯
    * 모델이 돌아가긴 해서 레이어를 중첩해보려고 하는데 LSTM input dimensions 문제가 계속 발생한다.
    * expected lstm_1_input to have 3 dimensions, but got array with shape (215, 1)  이거 정체가 뭐냐
    * 나이거 ㄹㅇ 모르겠어 따흐흙

* 9일차
    * demensions 에러를 고쳤다! 에러를 고칠줄은 아는데 이유는 모르겠다. 막 하다보니까 되는겨
    * In a stateful network, you should only pass inputs with a number of samples that can be divided by the batch size 이젠 종종 이 에러가 문제다
    * 나는 batch size를 직접 지정했는데도 batch_size가 32라고 에러가 종종 뜬다.
    * Neural 스택을 쌓지만 않으면 에러가 발생하지 않는다. 왜 쌓으면 에러가 나는거지... 쌓아보고싶어요ㅠㅠ

* 10일차
    * Feature 가 늘었다!! Days of Week, Tags(게시물의 태그, 약 15개쯤 된다), Time of Day 이렇게 3가지의 Feature 가 생겼다.
    * 주어진 Feature 에 따라 방문자수를 예측하는 모델은 만든다.
    * 어떤 요일, 몇시, 어떤 태그의 posts 를 올려야 방문자수를 올릴 수 있는지 알아내는 것이 목적
    * 나중에 마케팅 팀에게 나보고 설명해달라는것 같은데 오또카지
    * 혹시나 해서 로드된 데이터를 출력해봤더니 엉망징짱이었따. 다시 로드 파트부터 시작해봐야겠다

* 11일차
    * 파일을 로드하는 파트부터 하나하나 전부 분석했다. 파일을 어떻게 불러오는지 어떤 모습의 형태로 전달이 되는지 전부 print 해보면서 확인했다.
    * 코드를 이해하고나니 오류가 한번에 해결되었다. 진작에 이렇게 할걸

* 12일차
    * 베이스라인 모델을 완성했다.
    * Paul 에게서 아직 제대로 된 데이터를 받지 못했기 때문에 엑셀의 Random 함수를 사용하여 슈도 데이터셋으로 테스트를 했다. >> 당연히 결과가 이상하다
    * 모델을 테스트 하기 위해 주식 데이터셋을 이용했다. 정상적으로 예측하고 있다.
    * 할게 없어서 Mysql workbench 로 데이터베이스 연습
    * 1시부터 Christmas party~ yeah~




* 15일차
    * 이제 문제는 매틀랩 그래프로 나오는 단위를 바꿔야한다... 이건 또 어떡하지
    * Firebase 에 있는 posts 수가 이상하기 때문에 Yee 가 준 엑셀파일에 있는 posts 와 firebase의 impressions, timestamp 를 수작업으로 정렬해야한다.
    * 파이썬을 이용하여 타임스탬프를 날짜로 바꾸는 코드를 짜고있다.
    * 타임스탬프를 날짜로 변환하고 날짜에 따른 요일코드(1~7), 그리고 DB value 3개의 칼럼은 하나의 리스트로 합쳐 csv 파일로 저장하는 코드를 작성하였다.

* 16일차
    * Paul 이 준 데이터를 기반으로 데이터셋을 만들어서 내 모델을 학습시켜 봤다.
    * 데이터셋이 너무 부족하다 적어도 천개정도는 있었으면 좋겠는데

* 17일차
    * 데이터가 너무 부족해서 왜곡시키는 방법으로 데이터셋을 늘려서 실험해볼 생각이다.
    * 근데 어느샌가 갑자기 예측 값이 이상해졌다. 갑자기 val_loss 가 솟구치기 시작했다. 내가 뭘 건드렸더라

* 18일차
    * 하이퍼파라미터 찾는거 너무 힘들다 기다리는게 너무 힘들다 구글 클라우드 플랫폼을 쓸줄 알아야하는데 너무 어렵다.
    * 이제 파이어베이스에 제대로된 posts 수가 올라올 때 까지 주어진 데이터로 하이퍼파라미터를 찾아야 한다.
    * 트레이닝 돌리면서 Pothole Detection 프로젝트를 다시 시작했다.

* 19일차
    * 계속 하이퍼파라미터를 찾는 중
    * Pothole Detection 에 관해선 데이터셋을 데이터1번가에 신청해놓았다. 진동데이터든 사진데이터든 있으면 좋겠다.
    * 데이터 스트림을 어떻게 학습시켜야 할지 모르겠다. 패턴인식 문제와 비슷하다고 하는 것 같긴한데 아직 잘 모르겠다.
    * 예측된 Y 가 정규분포 형태로 나오는걸 원래 모습으로 되돌리는 코드를 넣는걸 깜빡하고 있었다.




* 22일차
    * 학습 시간 기다리는게 너무 지루해서 구글 클라우드 플랫폼을 다루는 법을 공부했지만 역시 어려워서 실패
    * 학습이 끝난 모델을 저장하고 불러오는데에 성공했지만 입력이 다른것이 문제
    * 학습을 할땐 page_impressions 까지 총 3개의 Feature 가 있지만 예측을 할 땐 page_impressions 을 예측해야 하므로 주어지는 Feature 는 요일과 posts 수 두개 뿐
    * 여기서 input_dimension 에러가 난다. 이 에러 해결 중

* 23일차
    * 첫번째 LSTM 레이어에 전해지는 배열은 3차원 배열인데 현재 Input 은 2차원이다.
    * pandas 로 test 데이터를 읽어들인 후 3차원으로 바꿔주는 코드를 복붙해오면 될것같긴 하다.
    * 3차원으로 바꾸더라도 feature 수가 2라서 돌아가질 않는다. 일단  test 데이터에서 칼럼 하나를 (train 에서 page_impressions 자리) 0으로 채워놨다.
    * 그냥 train 과정에서 X 에 page_impressions 를 빼버리는 것도 괜찮을듯
    * 일단 Yee 와 Paul 로 부터 2016년 7월 19일부터 현재까지의 page_impressions 와 posts 데이터를 받았다. 퇴근까지 10분 남았으므로 train 은 내일한다 ㅎㅎ 가즈아ㅏㅏㅏ

* 24일차
    * 하루종일 트레이닝만 시켰다.
    * 예상과는 달리 더 많은 데이터가 생겼음에도 예측 그래프가 오리지널 그래프를 전혀 따라가지 못하고있다.
    * 혹시나 해서 요일을 1~7이 아닌 0 0 0 0 0 1 0  이렇게 2진 형식으로 바꿔서 feature 를 늘려봤지만 조금 비슷한 수치를 가지긴 해도 너무 오차가 심하다
    * 모델이 잘못된건가 싶어 주식 데이터를 넣어봤지만 퇴근 시간이 되어 종료시켜버렸다 히히

* 25일차
    * 어제 시간이 없어 train 시켜보지 못했던 주식 데이터를 넣어서 트레이닝 시켜보았다.
    * 와 개엉망으로 나오네 이거 왜이러지

* 26일차
    * 조금씩 epoch를 올리니까 점점 오리지널 그래프에 가까이 가기는 한다.
    * 1만사이클을 돌려놓고 구글 클라우드 플랫폼을 공부하고 있다.



-- 2주 휴가(12.23 ~ 1.7) --



* 43일차
    * 2주 휴가받고 놀고왔더니 내가 했던거 다 까먹은 기분이다. 이렇게라도 기록해놔서 다행이다.
    * 휴가기간동안 구글 클라우드를 이용하여 로컬로 트레이닝 시키는데에 성공했다.
    * 오늘은 구글 클라우드에서 트레이닝 시키는걸 시도중인데 계속 에러가나냐

* 44일차
    * 구글 클라우드는 한결같이 같은 에러가 난다 이유가 뭐지
    * 갑자기 궁금해졌는데 요일을 1~7로 하는거랑  0 0 0 0 1 이런식으로 하는거랑 어느쪽이 더 괜찮은 방법인지 궁금해졌다
    * 학습된 모델을 불러오는것도 문제다.
    * 일주일치 게시물 수에 따른 방문자수를 예측하는데 학습시킬때 시퀀스가 5였으면 예측할 날로부터 5일  전까지의 데이터를 같이 입력해야하는건가?

* 45일차
    * 학습과정에서 주식 예측 처럼 이전 방문자수까지 feature 로 넘겼기 때문에 LSTM의 첫 Input shape가 (None, None, 9) 이다.
    * 하지만 예측할때의 data 는 page_impressions이 없는 (None, None, 8) 모습이다.
    * 학습과 예측의 data feature 수가 다르다.
    * 예측된 Y를 다시 입력으로 넣는 방식으로 반복하면 해결될 것 같기도 한데 keras 라이브러리의 predict 함수가 어떻게 돌아가는지 모르겠다

* 46일차
    * 어제와 똑같은 일을 반복했다. 아무리 찾아도 안나온다 어디있는거냐아아
    * 아무리 찾아도 안나와서 지식인에 질문을 올렸다 ㅋㅋ
    * 일단 정규화된 Y값을 되돌리는 코드부터 완성해야겠다.

* 47일차
    * 으아 이제 일주일 남았는데 프로젝트 다 못끝냈다
    * 전처리 함수 내에서 정규화 함수를 옮기려면 건들게 너무 많아진다.
    * 정규화 과정을 model.fit(x_train, y_train...) 에 넣기 직전에 수행해보려 한다.
    * 데이터와 라벨은 서로 다른 최소, 최대값을 가지고 있으므로 각자의 scaler 를 가지고 있어야 한댄다. 맞는지는 모름
